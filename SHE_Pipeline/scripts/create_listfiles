#!/usr/bin/env python

""" @file create_listfiles.py

    Created 15 July 2019

    Script to search through the current directory for MER and VIS products, and create listfiles for running of
    Analysis and Reconciliation pipelines for all observation IDs and Tile IDs.

    Must be run with E-Run.
"""

__updated__ = "2022-01-14"

# Copyright (C) 2012-2020 Euclid Science Ground Segment
#
# This library is free software; you can redistribute it and/or modify it under the terms of the GNU Lesser General
# Public License as published by the Free Software Foundation; either version 3.0 of the License, or (at your option)
# any later version.
#
# This library is distributed in the hope that it will be useful, but WITHOUT ANY WARRANTY; without even the implied
# warranty of MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the GNU Lesser General Public License for more
# details.
#
# You should have received a copy of the GNU Lesser General Public License along with this library; if not, write to
# the Free Software Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA 02110-1301 USA

import os
from collections import namedtuple
from enum import Enum

from SHE_PPT.file_io import read_xml_product, write_listfile
from SHE_PPT.logging import getLogger
from SHE_PPT.products.mer_final_catalog import dpdMerFinalCatalog
from SHE_PPT.products.mer_segmentation_map import dpdMerSegmentationMap
from SHE_PPT.products.she_exposure_segmentation_map import dpdSheExposureReprojectedSegmentationMap
from SHE_PPT.products.she_lensmc_chains import dpdSheLensMcChains
from SHE_PPT.products.she_stack_segmentation_map import dpdSheStackReprojectedSegmentationMap
from SHE_PPT.products.she_validated_measurements import dpdSheValidatedMeasurements
from SHE_PPT.products.tu_gal_cat import dpdGalaxyCatalogProduct
from SHE_PPT.products.tu_output_cat import dpdTrueUniverseOutput
from SHE_PPT.products.tu_star_cat import dpdStarsCatalogProduct
from SHE_PPT.products.vis_calibrated_frame import dpdVisCalibratedFrame
from SHE_PPT.products.vis_stacked_frame import dpdVisStackedFrame
from SHE_PPT.utility import get_nested_attr
from ST_DM_MDBTools.Mdb import Mdb

logger = getLogger(__name__)

ROOT_DIR = "."

ANALYSIS_ISF_HEAD = "analysis_"
ANALYSIS_ISF_TAIL = "_isf.txt"

AFTER_REMAP_TAG = "after_remap_"
VALIDATION_TAG = "with_validation_"

ANALYSIS_VALIDATION_ISF_HEAD = "analysis_validation_"
ANALYSIS_VALIDATION_ISF_TAIL = "_isf.txt"

RECONCILIATION_ISF_HEAD = "reconciliation_"
RECONCILIATION_ISF_TAIL = "_isf.txt"

mdb_filename = "sample_mdb-SC8.xml"


class ProdKeys(Enum):
    # Dict keys Enum
    MFC = "MER Final Catalogue"
    MSEG = "MER Segmentation Map"
    SESEG = "SHE Exposure Reprojected Segmentation Map"
    SSSEG = "SHE Stack Reprojected Segmentation Map"
    SVM = "SHE Validated Measurements"
    SLMC = "SHE LensMC Chains"
    VCF = "VIS Calibrated Frame"
    VSF = "VIS Stacked Frame"
    TUG = "TU Galaxy Catalog"
    TUS = "TU Star Catalog"
    TUO = "TU Output Product"


ANALYSIS_PRODUCT_KEYS = (ProdKeys.MFC, ProdKeys.MSEG, ProdKeys.SESEG, ProdKeys.SSSEG,
                         ProdKeys.VCF, ProdKeys.VSF, ProdKeys.TUO)

ANALYSIS_VALIDATION_PRODUCT_KEYS = (ProdKeys.MFC, ProdKeys.VCF, ProdKeys.SVM, ProdKeys.SLMC, ProdKeys.TUO)

RECONCILIATION_PRODUCT_KEYS = (ProdKeys.MFC, ProdKeys.SVM, ProdKeys.SLMC,)

# Which pipelines a given product is used for
# 1 = only for that variant, -1 = only not that variant, 0 = both variants
ONLY_FOR_AFTER_REMAP = {ProdKeys.MFC: 0,
                        ProdKeys.MSEG: -1,
                        ProdKeys.SESEG: 1,
                        ProdKeys.SSSEG: 1,
                        ProdKeys.VCF: 0,
                        ProdKeys.VSF: 0,
                        ProdKeys.TUO: 0,
                        }
ONLY_FOR_VALIDATION = {ProdKeys.MFC: 0,
                       ProdKeys.MSEG: 0,
                       ProdKeys.SESEG: 0,
                       ProdKeys.SSSEG: 0,
                       ProdKeys.VCF: 0,
                       ProdKeys.VSF: 0,
                       ProdKeys.TUO: 1,
                       }

# ISF ports and common filenames

ANALYSIS_ISF_PORTS = {ProdKeys.MFC: "mer_final_catalog_listfile",
                      ProdKeys.MSEG: "mer_segmentation_map_listfile",
                      ProdKeys.SESEG: "she_exposure_reprojected_segmentation_map_listfile",
                      ProdKeys.SSSEG: "she_stack_reprojected_segmentation_map",
                      ProdKeys.VCF: "vis_calibrated_frame_listfile",
                      ProdKeys.VSF: "vis_stacked_frame",
                      ProdKeys.TUO: "tu_output_product",
                      }

FIXED_ANALYSIS_ISF_FILENAMES = ["phz_output_cat = None",
                                "ksb_training_data = test_ksb_training.xml",
                                "lensmc_training_data = test_lensmc_training.xml",
                                "momentsml_training_data = None",
                                "regauss_training_data = test_regauss_training.xml",
                                "spe_output_cat = None"]

ANALYSIS_VALIDATION_ISF_PORTS = {ProdKeys.MFC: "mer_final_catalog_listfile",
                                 ProdKeys.VCF: "vis_calibrated_frame_listfile",
                                 ProdKeys.SVM: "she_validated_measurements",
                                 ProdKeys.SLMC: "she_lensmc_chains",
                                 ProdKeys.TUO: "tu_output_product",
                                 }

RECONCILIATION_ISF_PORTS = {ProdKeys.MFC: "mer_final_catalog",
                            ProdKeys.SVM: "she_validated_measurements_listfile",
                            ProdKeys.SLMC: "she_lensmc_chains_listfile",
                            }

# Product types

PRODUCT_TYPES = {ProdKeys.MFC: dpdMerFinalCatalog,
                 ProdKeys.MSEG: dpdMerSegmentationMap,
                 ProdKeys.SESEG: dpdSheExposureReprojectedSegmentationMap,
                 ProdKeys.SSSEG: dpdSheStackReprojectedSegmentationMap,
                 ProdKeys.SVM: dpdSheValidatedMeasurements,
                 ProdKeys.SLMC: dpdSheLensMcChains,
                 ProdKeys.VCF: dpdVisCalibratedFrame,
                 ProdKeys.VSF: dpdVisStackedFrame,
                 ProdKeys.TUG: dpdGalaxyCatalogProduct,
                 ProdKeys.TUS: dpdStarsCatalogProduct,
                 ProdKeys.TUO: dpdTrueUniverseOutput,
                 }

# Desired filename info

FILENAME_HEADS = {ProdKeys.MFC: "mer_final_catalog_obs_",
                  ProdKeys.MSEG: "mer_segmentation_map_obs_",
                  ProdKeys.SESEG: "she_exposure_reprojected_segmentation_map_obs_",
                  ProdKeys.SSSEG: "she_stack_reprojected_segmentation_map_obs_",
                  ProdKeys.SVM: {"Analysis": "she_validated_measurements_obs_",
                                 "Reconciliation": "she_validated_measurements_tile_"},
                  ProdKeys.SLMC: {"Analysis": "she_lensmc_chains_obs_",
                                  "Reconciliation": "she_lensmc_chains_tile_"},
                  ProdKeys.VCF: "vis_calibrated_frame_obs_",
                  ProdKeys.VSF: None,
                  ProdKeys.TUG: "galcats",
                  ProdKeys.TUS: "starcats",
                  ProdKeys.TUO: "tu_output",
                  }

FILENAME_TAILS = {ProdKeys.MFC: "_listfile.json",
                  ProdKeys.MSEG: "_listfile.json",
                  ProdKeys.SESEG: "_listfile.json",
                  ProdKeys.SSSEG: "_product.xml",
                  ProdKeys.SVM: {"Analysis": "_product.xml",
                                 "Reconciliation": "_listfile.json"},
                  ProdKeys.SLMC: {"Analysis": "_product.xml",
                                  "Reconciliation": "_listfile.json"},
                  ProdKeys.VCF: "_listfile.json",
                  ProdKeys.VSF: None,
                  ProdKeys.TUG: ".json",
                  ProdKeys.TUS: ".json",
                  ProdKeys.TUO: "_product.xml",
                  }

# A namedtuple type for all data of each product type
ProductTypeData = namedtuple("ProductTypeData", ["type",
                                                 "full_list",
                                                 "obs_id_dict",
                                                 "tile_id_dict",
                                                 "filename_head",
                                                 "filename_tail"])

# A namedtuple type for a filename and product
FileProduct = namedtuple("FileProduct", ["filename", "product"])

# Init dict of data for each product type
product_type_data_dict = {}
for key in ANALYSIS_PRODUCT_KEYS + ANALYSIS_VALIDATION_PRODUCT_KEYS + RECONCILIATION_PRODUCT_KEYS:
    product_type_data_dict[key] = ProductTypeData(PRODUCT_TYPES[key],
                                                  [],
                                                  {},
                                                  {},
                                                  FILENAME_HEADS[key],
                                                  FILENAME_TAILS[key])

# Get all existing products, read them in, and sort them depending on type

all_filenames = os.listdir(ROOT_DIR)

for filename in all_filenames:

    if filename[-4:] != ".xml":
        continue

    try:
        product = read_xml_product(filename, workdir=ROOT_DIR)
    except Exception:

        logger.info("Can't read XML product, trying if it's in MDB format...")

        # Check if it's in MDB format
        try:
            Mdb(os.path.join(ROOT_DIR, filename))
            mdb_filename = filename
            logger.info(f"{filename} seems to be an MDB file.")
            continue
        except Exception:
            raise ValueError("Can't interpret file " + filename)

    identified_product = False

    # Find the type of the product and add it to the appropriate list
    for product_key in ANALYSIS_PRODUCT_KEYS + RECONCILIATION_PRODUCT_KEYS:

        product_type_data = product_type_data_dict[product_key]

        if not isinstance(product, product_type_data.type):
            continue

        identified_product = True

        # Add this to the full list for the product
        product_type_data.full_list.append(FileProduct(filename, product))

    if not identified_product:
        logger.warning(f"Cannot identify type of product {filename}")

logger.info(f"Read in data products.")

# Get sets of all Observation and Tile IDs
observation_id_set = set()
tile_id_set = set()

# Fill in the obs_id_dicts for all product types
for prod_key, attr, is_list in ((ProdKeys.SESEG, "Data.ObservationId", False),
                                (ProdKeys.SSSEG, "Data.ObservationId", False),
                                (ProdKeys.SVM, "Data.ObservationId", False),
                                (ProdKeys.SLMC, "Data.ObservationId", False),
                                (ProdKeys.VSF, "Data.ObservationId", False),
                                (ProdKeys.VCF, "Data.ObservationSequence.ObservationId", False),
                                (ProdKeys.MFC, "Data.ObservationIdList", True),
                                (ProdKeys.MSEG, "Data.ObservationIdList", True),
                                (ProdKeys.TUO, "Data.EuclidPointingId", False),
                                ):
    product_type_data = product_type_data_dict[prod_key]
    for fileprod in product_type_data.full_list:
        obs_id_or_list = get_nested_attr(fileprod.product, attr)
        if is_list:
            # List of IDs, so iterate over it and add to each list
            for obs_id in obs_id_or_list:
                if obs_id in product_type_data.obs_id_dict:
                    if fileprod not in product_type_data.obs_id_dict[obs_id]:
                        product_type_data.obs_id_dict[obs_id].append(fileprod)
                else:
                    product_type_data.obs_id_dict[obs_id] = [fileprod]
                    observation_id_set.add(obs_id)
        else:
            # Just one ID, so add it directly
            if obs_id_or_list in product_type_data.obs_id_dict:
                if fileprod not in product_type_data.obs_id_dict[obs_id_or_list]:
                    product_type_data.obs_id_dict[obs_id_or_list].append(fileprod)
            else:
                product_type_data.obs_id_dict[obs_id_or_list] = [fileprod]
                observation_id_set.add(obs_id_or_list)

logger.info(f"Identified the following Observation IDs: {observation_id_set}")

# Fill in the tile_id_dicts for all product types
for prod_key, attr, is_tile in ((ProdKeys.MFC, "Data.TileIndex", True),
                                (ProdKeys.MSEG, "Data.TileIndex", True),
                                (ProdKeys.SESEG, "Data.ObservationId", False),
                                (ProdKeys.SSSEG, "Data.ObservationId", False),
                                (ProdKeys.SVM, "Data.ObservationId", False),
                                (ProdKeys.SLMC, "Data.ObservationId", False),
                                (ProdKeys.VCF, "Data.ObservationSequence.ObservationId", False),
                                (ProdKeys.VSF, "Data.ObservationId", False),
                                (ProdKeys.TUO, "Data.EuclidPointingId", False),
                                ):
    product_type_data = product_type_data_dict[prod_key]
    for fileprod in product_type_data.full_list:
        if is_tile:
            tile_ids = [get_nested_attr(fileprod.product, attr)]
        else:
            # This is an observation product, so we'll have to find its corresponding tiles indirectly
            obs_id = get_nested_attr(fileprod.product, attr)
            tile_ids = []
            for final_catalog_fileprod in product_type_data_dict[ProdKeys.MFC].full_list:
                if obs_id in final_catalog_fileprod.product.Data.ObservationIdList:
                    tile_ids.append(final_catalog_fileprod.product.Data.TileIndex)
        for tile_id in tile_ids:
            if tile_id in product_type_data.tile_id_dict:
                if fileprod not in product_type_data.tile_id_dict[tile_id]:
                    product_type_data.tile_id_dict[tile_id].append(fileprod)
            else:
                product_type_data.tile_id_dict[tile_id] = [fileprod]
                tile_id_set.add(tile_id)

logger.info(f"Identified the following Tile IDs: {tile_id_set}")

if len(observation_id_set) == 0:
    logger.error("No observation IDs found.")
    exit()

if len(tile_id_set) == 0:
    logger.error("No tile IDs found.")
    exit()

analysis_filename_dict = {}
reconciliation_filename_dict = {}

# Write Analysis listfiles for the galaxy and star catalogues
if ProdKeys.TUG in ANALYSIS_PRODUCT_KEYS and ProdKeys.TUS in ANALYSIS_PRODUCT_KEYS:

    logger.info("Writing TU Galaxy and Star Catalog listfiles.")

    for prod_key in (ProdKeys.TUG, ProdKeys.TUS):

        product_type_data = product_type_data_dict[prod_key]
        filename = product_type_data.filename_head + product_type_data.filename_tail
        analysis_filename_dict[prod_key] = filename

        fileprod_list = product_type_data.full_list

        filename_list = [fileprod.filename for fileprod in fileprod_list]

        write_listfile(os.path.join(ROOT_DIR, filename), filename_list)

    logger.info("Finished writing TU Galaxy and Star Catalog listfiles.")

logger.info("Writing Analysis listfiles and ISFs.")

analysis_valid = {}

# Set up Analysis listfiles and ISFs for each observation ID
for obs_id in observation_id_set:

    logger.info(f"Writing Analysis listfiles and ISFs for observation ID {obs_id}.")

    analysis_valid[obs_id] = True

    # Set up and write the listfiles
    for prod_key, sort_by in ((ProdKeys.MFC, "Data.TileIndex"),
                              (ProdKeys.MSEG, "Data.TileIndex"),
                              (ProdKeys.SESEG, "Data.PointingId"),
                              (ProdKeys.VCF, "Data.ObservationSequence.PointingId"),
                              ):

        product_type_data = product_type_data_dict[prod_key]

        filename = product_type_data.filename_head + str(obs_id) + product_type_data.filename_tail
        analysis_filename_dict[prod_key] = filename

        if obs_id not in product_type_data.obs_id_dict:
            if prod_key != ProdKeys.SESEG:
                # This product isn't present, so skip it and mark as invalid for the analysis pipeline
                analysis_valid[obs_id] = False
            logger.warning(f"Product type {prod_key.value} not present for observation ID {obs_id}.")
            continue

        obs_fileprod_list = product_type_data.obs_id_dict[obs_id]
        obs_fileprod_list.sort(key=lambda fp: get_nested_attr(fp.product, sort_by))

        obs_filename_list = [obs_fileprod.filename for obs_fileprod in obs_fileprod_list]

        write_listfile(os.path.join(ROOT_DIR, filename), obs_filename_list)

    if not analysis_valid[obs_id]:
        continue

    # Set the filename for products we only have one of per observation

    analysis_filename_dict[ProdKeys.VSF] = product_type_data_dict[ProdKeys.VSF].obs_id_dict[obs_id][0].filename

    if obs_id in product_type_data_dict[ProdKeys.SSSEG].obs_id_dict:
        analysis_filename_dict[ProdKeys.SSSEG] = product_type_data_dict[ProdKeys.SSSEG].obs_id_dict[obs_id][0].filename
    else:
        logger.warning(
            "Stack reprojected segmentation map product not available; default filename will be used in ISFs.")
        analysis_filename_dict[ProdKeys.SSSEG] = (product_type_data_dict[ProdKeys.SSSEG].filename_head +
                                                  str(obs_id) + product_type_data_dict[ProdKeys.SSSEG].filename_tail)

    if obs_id in product_type_data_dict[ProdKeys.SVM].obs_id_dict:
        analysis_filename_dict[ProdKeys.SVM] = product_type_data_dict[ProdKeys.SVM].obs_id_dict[obs_id][0].filename
    else:
        logger.warning("Validated Shear Measurements product not available; default filename will be used in ISFs.")
        analysis_filename_dict[ProdKeys.SVM] = (product_type_data_dict[ProdKeys.SVM].filename_head["Analysis"] +
                                                str(obs_id) + product_type_data_dict[ProdKeys.SVM].filename_tail[
                                                    "Analysis"])

    if obs_id in product_type_data_dict[ProdKeys.SLMC].obs_id_dict:
        analysis_filename_dict[ProdKeys.SLMC] = product_type_data_dict[ProdKeys.SLMC].obs_id_dict[obs_id][0].filename
    else:
        logger.warning("LensMC Chains product not available; default filename will be used in ISFs.")
        analysis_filename_dict[ProdKeys.SLMC] = (product_type_data_dict[ProdKeys.SLMC].filename_head["Analysis"] +
                                                 str(obs_id) + product_type_data_dict[ProdKeys.SLMC].filename_tail[
                                                     "Analysis"])

    if obs_id in product_type_data_dict[ProdKeys.TUO].obs_id_dict:
        analysis_filename_dict[ProdKeys.TUO] = product_type_data_dict[ProdKeys.TUO].obs_id_dict[obs_id][0].filename
    else:
        logger.warning("True Universe Output Product not available; default filename will be used in ISFs.")
        analysis_filename_dict[ProdKeys.TUO] = (product_type_data_dict[ProdKeys.TUO].filename_head +
                                                str(obs_id) + product_type_data_dict[ProdKeys.TUO].filename_tail)

    # Write the ISF for this observation for each variant
    for after_remap in (False, True):
        for with_validation in (False, True):

            # Get the filename for this specific variant
            isf_filename = ANALYSIS_ISF_HEAD
            if after_remap:
                isf_filename += AFTER_REMAP_TAG
            if with_validation:
                isf_filename += VALIDATION_TAG
            isf_filename += str(obs_id) + ANALYSIS_ISF_TAIL

            # Write the ISF
            with open(isf_filename, "w") as fo:
                # Write these listfile filenames to the ISF
                for prod_key in ANALYSIS_PRODUCT_KEYS:
                    # Determine whether to write this key or not from the variant
                    met_criteria = True
                    for criteria, variant in ((ONLY_FOR_AFTER_REMAP[prod_key], after_remap),
                                              (ONLY_FOR_VALIDATION[prod_key], with_validation)):
                        if (criteria == 1 and not variant) or (criteria == -1 and variant):
                            met_criteria = False
                    if met_criteria:
                        fo.write(f"{ANALYSIS_ISF_PORTS[prod_key]} = {analysis_filename_dict[prod_key]}\n")
                # Write the fixed product filenames to the ISF
                for l in FIXED_ANALYSIS_ISF_FILENAMES:
                    fo.write(l + "\n")
                # Write the MDB port
                fo.write(f"mdb = {mdb_filename}\n", )

    logger.info(f"Finished writing Analysis listfiles and ISF for observation ID {obs_id}.")

logger.info("Finished writing Analysis listfiles and ISFs.")

# Write the ISF for the Analysis Validation pipeline

logger.info("Writing Analysis Validation ISFs.")
for obs_id in observation_id_set:

    if not analysis_valid[obs_id]:
        continue

    logger.info(f"Writing Analysis Validation ISF for observation ID {obs_id}.")

    isf_filename = f"{ANALYSIS_VALIDATION_ISF_HEAD}{obs_id}{ANALYSIS_ISF_TAIL}"

    # Write the ISF
    with open(isf_filename, "w") as fo:
        # Write these listfile filenames to the ISF
        for prod_key in ANALYSIS_VALIDATION_PRODUCT_KEYS:
            fo.write(f"{ANALYSIS_VALIDATION_ISF_PORTS[prod_key]} = {analysis_filename_dict[prod_key]}\n")

    logger.info(f"Finished writing Analysis Validation ISF for observation ID {obs_id}.")

logger.info("Finished writing Analysis Validation ISFs.")

logger.info("Writing Reconciliation listfiles and ISFs.")

# Set up Reconciliation listfiles and ISFs for each Tile ID
for tile_id in tile_id_set:

    logger.info(f"Writing Reconciliation listfiles and ISFs for tile ID {tile_id}.")

    tile_valid = True

    if tile_id not in product_type_data_dict[ProdKeys.MFC].tile_id_dict:
        continue

    reconciliation_filename_dict[ProdKeys.MFC] = product_type_data_dict[ProdKeys.MFC].tile_id_dict[tile_id][0].filename

    # Set up and write the listfiles
    for prod_key, sort_by in ((ProdKeys.SVM, "Data.ObservationId"),
                              (ProdKeys.SLMC, "Data.ObservationId"),
                              ):

        product_type_data = product_type_data_dict[prod_key]

        if tile_id not in product_type_data.tile_id_dict:
            tile_valid = False
            logger.warning(f"Product type {prod_key.value} not present for tile ID {tile_id}.")
            break

        filename = product_type_data.filename_head + str(tile_id) + product_type_data.filename_tail
        reconciliation_filename_dict[prod_key] = filename

        obs_fileprod_list = product_type_data.tile_id_dict[tile_id]
        obs_fileprod_list.sort(key=lambda fp: get_nested_attr(fp.product, sort_by))

        obs_filename_list = [obs_fileprod.filename for obs_fileprod in obs_fileprod_list]

        write_listfile(os.path.join(ROOT_DIR, filename), obs_filename_list)

    if not tile_valid:
        continue

    # Write the ISF for this tile
    isf_filename = RECONCILIATION_ISF_HEAD + str(tile_id) + RECONCILIATION_ISF_TAIL
    with open(isf_filename, "w") as fo:
        # Write these listfile filenames to the ISF
        for prod_key in RECONCILIATION_PRODUCT_KEYS:
            fo.write(f"{RECONCILIATION_ISF_PORTS[prod_key]} = {reconciliation_filename_dict[prod_key]}\n")

    logger.info(f"Finished writing Reconciliation listfiles and ISFs for tile ID {tile_id}.")

logger.info("Finished writing Reconciliation listfiles and ISFs.")

logger.info("Script execution complete.")
